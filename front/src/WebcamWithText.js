import React, { useRef, useEffect, useState } from "react";
import * as ort from "onnxruntime-web";
import DraggableText from "./DraggableText";

export default function WebcamWithText({ blocks, setBlocks, selectedBlockId, setSelectedBlockId, onStatsUpdate }) {
  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const containerRef = useRef(null);
  const [session, setSession] = useState(null);
  const recRef = useRef([]);
  const backgroundRef = useRef(null);
  const frameCountRef = useRef(0);
  const totalTimeRef = useRef(0);
  const lastStatsUpdateRef = useRef(0); // –î–ª—è throttling –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
  const downsampleCanvasRef = useRef(null); // Canvas –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
  const maskCanvasRef = useRef(null); // Canvas –¥–ª—è –º–∞—Å–∫–∏ —É–º–µ–Ω—å—à–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
  const fullMaskCanvasRef = useRef(null); // Canvas –¥–ª—è –º–∞—Å–∫–∏ –ø–æ–ª–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
  
  // –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —É–º–µ–Ω—å—à–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏ (0.4 = 40% –æ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª–∞)
  // –ú–µ–Ω—å—à–µ –∑–Ω–∞—á–µ–Ω–∏–µ = –±—ã—Å—Ç—Ä–µ–µ —Ä–∞–±–æ—Ç–∞, –Ω–æ –Ω–∏–∂–µ –∫–∞—á–µ—Å—Ç–≤–æ
  // –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: 0.3-0.5
  const MODEL_SCALE = 0.4;
  const downsampleRatioQuality = 0.6;

  useEffect(() => {
    // –°–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ canvas –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞ –∫–∞–∂–¥–æ–º –∫–∞–¥—Ä–µ)
    downsampleCanvasRef.current = document.createElement('canvas');
    maskCanvasRef.current = document.createElement('canvas');
    fullMaskCanvasRef.current = document.createElement('canvas');
    
    // –ü–æ–ª—É—á–∞–µ–º –ø–æ—Ç–æ–∫ —Å –∫–∞–º–µ—Ä—ã
    navigator.mediaDevices
      .getUserMedia({ video: true })
      .then((stream) => {
        if (videoRef.current) {
          videoRef.current.srcObject = stream;
          videoRef.current.play().catch(console.error);
        }
      })
      .catch(console.error);

    // –ù–∞—Å—Ç—Ä–æ–π–∫–∞ ONNX Runtime - –ø—Ä–æ—Å—Ç–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –±–µ–∑ –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç–∏
    ort.env.wasm.numThreads = 1;  // –û–¥–Ω–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç—å (–Ω–µ —Ç—Ä–µ–±—É–µ—Ç crossOriginIsolation)
    ort.env.wasm.simd = true;     // SIMD –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
    
    // –ó–∞–≥—Ä—É–∑–∫–∞ ONNX –º–æ–¥–µ–ª–∏
    console.log("üîÑ Loading model...");
    ort.InferenceSession.create("/rvm_mobilenetv3_fp32.onnx", {
      executionProviders: ['webgl', 'wasm']  // –°—Ç–∞–±–∏–ª—å–Ω—ã–π WASM backend
    }).then((sess) => {
      console.log("‚úÖ Model loaded successfully!");
      console.log("üéÆ Backend:", "WASM (CPU with SIMD)");
      console.log("üìä Input names:", sess.inputNames);
      setSession(sess);
      // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è recurrent states - –∏—Å–ø–æ–ª—å–∑—É–µ–º float32
      recRef.current = [
        new ort.Tensor("float32", new Float32Array(1).fill(0), [1, 1, 1, 1]),
        new ort.Tensor("float32", new Float32Array(1).fill(0), [1, 1, 1, 1]),
        new ort.Tensor("float32", new Float32Array(1).fill(0), [1, 1, 1, 1]),
        new ort.Tensor("float32", new Float32Array(1).fill(0), [1, 1, 1, 1])
      ];
    }).catch(console.error);

    // –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–æ–Ω–∞
    const bgCanvas = document.createElement('canvas');
    bgCanvas.width = 1280;
    bgCanvas.height = 960;
    const bgCtx = bgCanvas.getContext('2d');
    const gradient = bgCtx.createLinearGradient(0, 0, 1280, 960);
    gradient.addColorStop(0, '#1a1a2e');
    gradient.addColorStop(1, '#16213e');
    bgCtx.fillStyle = gradient;
    bgCtx.fillRect(0, 0, 1280, 960);
    backgroundRef.current = bgCtx.getImageData(0, 0, 1280, 960);
  }, []);

  useEffect(() => {
    let animationId;

    const drawFrame = async () => {
      if (!videoRef.current || !canvasRef.current) {
        animationId = requestAnimationFrame(drawFrame);
        return;
      }

      const video = videoRef.current;
      const canvas = canvasRef.current;
      const ctx = canvas.getContext("2d");

      // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤–∏–¥–µ–æ —É–∂–µ –∏–º–µ–µ—Ç —Ä–∞–∑–º–µ—Ä—ã
      if (video.videoWidth > 0 && video.videoHeight > 0) {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        if (session && recRef.current.length > 0) {
          const startTime = performance.now();

          // –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã
          const origWidth = canvas.width;
          const origHeight = canvas.height;
          
          // –£–º–µ–Ω—å—à–µ–Ω–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è –º–æ–¥–µ–ª–∏
          const modelWidth = Math.round(origWidth * MODEL_SCALE);
          const modelHeight = Math.round(origHeight * MODEL_SCALE);
          
          // –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π canvas –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
          const downsampleCanvas = downsampleCanvasRef.current;
          downsampleCanvas.width = modelWidth;
          downsampleCanvas.height = modelHeight;
          const downsampleCtx = downsampleCanvas.getContext('2d');
          
          // –†–∏—Å—É–µ–º —É–º–µ–Ω—å—à–µ–Ω–Ω–æ–µ –≤–∏–¥–µ–æ
          downsampleCtx.drawImage(video, 0, 0, modelWidth, modelHeight);
          const imageData = downsampleCtx.getImageData(0, 0, modelWidth, modelHeight);
          
          const rgbData = new Float32Array(3 * modelWidth * modelHeight);
          
          // –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ RGB –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è [0, 1]
          for (let i = 0; i < modelWidth * modelHeight; i++) {
            rgbData[i] = imageData.data[i * 4] / 255.0; // R
            rgbData[modelWidth * modelHeight + i] = imageData.data[i * 4 + 1] / 255.0; // G
            rgbData[2 * modelWidth * modelHeight + i] = imageData.data[i * 4 + 2] / 255.0; // B
          }

          // –ü–µ—Ä–µ–¥–∞—ë–º —É–º–µ–Ω—å—à–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –º–æ–¥–µ–ª—å
          const inputTensor = new ort.Tensor("float32", rgbData, [1, 3, modelHeight, modelWidth]);
          // downsample_ratio - –ø–∞—Ä–∞–º–µ—Ç—Ä –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏ (0.6 = —Ö–æ—Ä–æ—à–∏–π –±–∞–ª–∞–Ω—Å)
          const downsampleRatio = new ort.Tensor("float32", new Float32Array([downsampleRatioQuality]), [1]);

          try {
            // –ó–∞–ø—É—Å–∫ –º–æ–¥–µ–ª–∏
            const feeds = {
              src: inputTensor,
              r1i: recRef.current[0],
              r2i: recRef.current[1],
              r3i: recRef.current[2],
              r4i: recRef.current[3],
              downsample_ratio: downsampleRatio
            };

            // –ò–∑–º–µ—Ä–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ —Ç–æ–ª—å–∫–æ –¥–ª—è –º–æ–¥–µ–ª–∏
            const modelStartTime = performance.now();
            const results = await session.run(feeds);
            const modelInferenceTime = performance.now() - modelStartTime;
            
            // –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–æ–Ω–∏ –≤ —É–º–µ–Ω—å—à–µ–Ω–Ω–æ–º —Ä–∞–∑–º–µ—Ä–µ)
            const phaSmall = results.pha.data;  // –ú–∞—Å–∫–∞ —É–º–µ–Ω—å—à–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
            
            // –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ rec states
            if (results.r1o) recRef.current[0] = results.r1o;
            if (results.r2o) recRef.current[1] = results.r2o;
            if (results.r3o) recRef.current[2] = results.r3o;
            if (results.r4o) recRef.current[3] = results.r4o;

            // –†–∏—Å—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –≤–∏–¥–µ–æ –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π canvas
            ctx.drawImage(video, 0, 0, origWidth, origHeight);
            const originalImageData = ctx.getImageData(0, 0, origWidth, origHeight);
            
            // –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –º–∞—Å–∫—É –æ–±—Ä–∞—Ç–Ω–æ –¥–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
            // –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ canvas
            const maskCanvas = maskCanvasRef.current;
            maskCanvas.width = modelWidth;
            maskCanvas.height = modelHeight;
            const maskCtx = maskCanvas.getContext('2d');
            const maskImageData = maskCtx.createImageData(modelWidth, modelHeight);
            
            // –ó–∞–ø–æ–ª–Ω—è–µ–º —É–º–µ–Ω—å—à–µ–Ω–Ω—É—é –º–∞—Å–∫—É (grayscale)
            for (let i = 0; i < modelWidth * modelHeight; i++) {
              const alpha = Math.min(1, Math.max(0, phaSmall[i]));
              const alphaVal = alpha * 255;
              maskImageData.data[i * 4] = alphaVal;
              maskImageData.data[i * 4 + 1] = alphaVal;
              maskImageData.data[i * 4 + 2] = alphaVal;
              maskImageData.data[i * 4 + 3] = 255;
            }
            
            maskCtx.putImageData(maskImageData, 0, 0);
            
            // –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –º–∞—Å–∫—É –¥–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
            const fullMaskCanvas = fullMaskCanvasRef.current;
            fullMaskCanvas.width = origWidth;
            fullMaskCanvas.height = origHeight;
            const fullMaskCtx = fullMaskCanvas.getContext('2d');
            fullMaskCtx.drawImage(maskCanvas, 0, 0, origWidth, origHeight);
            const fullMaskData = fullMaskCtx.getImageData(0, 0, origWidth, origHeight);

            // –ö–æ–º–ø–æ–∑–∏—Ç–∏–Ω–≥ —Å —Ñ–æ–Ω–æ–º –∏—Å–ø–æ–ª—å–∑—É—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –≤–∏–¥–µ–æ –∏ —É–≤–µ–ª–∏—á–µ–Ω–Ω—É—é –º–∞—Å–∫—É
            const background = backgroundRef.current;
            const outputData = new Uint8ClampedArray(origWidth * origHeight * 4);
            
            for (let i = 0; i < origWidth * origHeight; i++) {
              const i4 = i * 4;
              const alpha = fullMaskData.data[i4] / 255.0;  // –ë–µ—Ä–µ–º –∞–ª—å—Ñ–∞ –∏–∑ —É–≤–µ–ª–∏—á–µ–Ω–Ω–æ–π –º–∞—Å–∫–∏
              const oneMinusAlpha = 1 - alpha;
              
              // –ë–µ—Ä–µ–º —Ü–≤–µ—Ç –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–∏–¥–µ–æ
              const r = originalImageData.data[i4];
              const g = originalImageData.data[i4 + 1];
              const b = originalImageData.data[i4 + 2];
              
              const bgR = background ? background.data[i4] : 26;
              const bgG = background ? background.data[i4 + 1] : 26;
              const bgB = background ? background.data[i4 + 2] : 46;
              
              outputData[i4] = r * alpha + bgR * oneMinusAlpha;
              outputData[i4 + 1] = g * alpha + bgG * oneMinusAlpha;
              outputData[i4 + 2] = b * alpha + bgB * oneMinusAlpha;
              outputData[i4 + 3] = 255;
            }

            const outputImageData = new ImageData(outputData, origWidth, origHeight);
            ctx.putImageData(outputImageData, 0, 0);

            // –†–∞—Å—á–µ—Ç FPS (–æ–±—â–µ–µ –≤—Ä–µ–º—è –∫–∞–¥—Ä–∞)
            const frameTime = performance.now() - startTime;
            totalTimeRef.current += frameTime;
            frameCountRef.current += 1;
            const fps = 1000.0 / frameTime;
            const avgFps = (frameCountRef.current * 1000.0) / totalTimeRef.current;

            // –û—Ç–ø—Ä–∞–≤–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç (throttled - —Ä–∞–∑ –≤ 100ms)
            const now = performance.now();
            if (onStatsUpdate && (now - lastStatsUpdateRef.current) > 100) {
              lastStatsUpdateRef.current = now;
              onStatsUpdate({
                fps: fps.toFixed(2),
                avgFps: avgFps.toFixed(2),
                modelTime: modelInferenceTime.toFixed(2), // –í—Ä–µ–º—è —Ç–æ–ª—å–∫–æ –º–æ–¥–µ–ª–∏
                fullFrameTime: frameTime.toFixed(2), // –ü–æ–ª–Ω–æ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–¥—Ä–∞
                modelActive: true
              });
            }
          } catch (error) {
            console.error("Model inference error:", error);
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            const now = performance.now();
            if (onStatsUpdate && (now - lastStatsUpdateRef.current) > 100) {
              lastStatsUpdateRef.current = now;
              onStatsUpdate({
                fps: null,
                avgFps: null,
                modelTime: null,
                fullFrameTime: null,
                modelActive: false
              });
            }
          }
        } else {
          ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
          const now = performance.now();
          if (onStatsUpdate && (now - lastStatsUpdateRef.current) > 100) {
            lastStatsUpdateRef.current = now;
            onStatsUpdate({
              fps: null,
              avgFps: null,
              modelTime: null,
              fullFrameTime: null,
              modelActive: false
            });
          }
        }
      }

      animationId = requestAnimationFrame(drawFrame);
    };

    animationId = requestAnimationFrame(drawFrame);

    return () => {
      if (animationId) {
        cancelAnimationFrame(animationId);
      }
    };
  }, [session]);

  const handleUpdate = (id, newProps) => {
    setBlocks((prev) => prev.map((b) => (b.id === id ? { ...b, ...newProps } : b)));
  };

  const handleBackgroundClick = () => setSelectedBlockId(null);

  return (
    <div
      ref={containerRef}
      style={{
        position: "relative",
        width: "1280px",
        height: "960px",
        overflow: "hidden",
      }}
      onClick={handleBackgroundClick}
    >
      <video
        ref={videoRef}
        autoPlay
        muted
        playsInline
        style={{ display: "none" }}
      />
      <canvas
        ref={canvasRef}
        style={{ width: "100%", height: "100%", background: "black" }}
      />

      {blocks.map((b) => (
        <DraggableText
          key={b.id}
          block={b}
          selected={b.id === selectedBlockId}
          onSelect={setSelectedBlockId}
          onUpdate={handleUpdate}
          parentRef={containerRef}
        />
      ))}
    </div>
  );
}
