"""
YOLO11 Segmentation —á–µ—Ä–µ–∑ ONNX Runtime
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç Ultralytics YOLO —Å ONNX backend –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
"""
import cv2
import numpy as np
import time
import argparse
from ultralytics import YOLO


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--model', type=str, required=True, help='–ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏')
    parser.add_argument('--device', type=str, default='cpu', choices=['cpu', 'cuda'])
    parser.add_argument('--conf', type=float, default=0.25)
    parser.add_argument('--iou', type=float, default=0.45)
    parser.add_argument('--camera', type=int, default=0)
    parser.add_argument('--width', type=int, default=None, help='–®–∏—Ä–∏–Ω–∞ –∫–∞–º–µ—Ä—ã (–º–µ–Ω—å—à–µ = –±—ã—Å—Ç—Ä–µ–µ)')
    parser.add_argument('--height', type=int, default=None, help='–í—ã—Å–æ—Ç–∞ –∫–∞–º–µ—Ä—ã (–º–µ–Ω—å—à–µ = –±—ã—Å—Ç—Ä–µ–µ)')
    parser.add_argument('--save', action='store_true')
    args = parser.parse_args()
    
    print("="*70)
    print("YOLO11 OPTIMIZED INFERENCE")
    print("="*70)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ ONNX Runtime
    try:
        import onnxruntime as ort
        providers = ort.get_available_providers()
        print(f"ONNX Runtime –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã: {providers}")
        
        if args.device == 'cuda' and 'CUDAExecutionProvider' not in providers:
            print("‚ö†Ô∏è CUDAExecutionProvider –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω!")
            print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip uninstall onnxruntime && pip install onnxruntime-gpu")
    except:
        pass
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ ONNX –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ Ultralytics
    print(f"–ó–∞–≥—Ä—É–∑–∫–∞: {args.model}")
    print(f"–ó–∞–ø—Ä–æ—à–µ–Ω–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {args.device.upper()}")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç –º–æ–¥–µ–ª–∏ –ø–æ –ø—É—Ç–∏
    model_format = "ONNX"
    if ".engine" in args.model:
        model_format = "TensorRT"
    elif "openvino" in args.model or "_openvino" in args.model:
        model_format = "OpenVINO"
    
    # –ü—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ (–Ω–µ 100% –Ω–∞–¥–µ–∂–Ω–æ)
    model_precision = "?"
    model_name_lower = args.model.lower()
    
    if "_half" in model_name_lower or "fp16" in model_name_lower or "_fp16" in model_name_lower:
        model_precision = "FP16"
    elif "int8" in model_name_lower or "_int8" in model_name_lower:
        model_precision = "INT8"
    elif "_fp32" in model_name_lower or model_format == "ONNX":
        model_precision = "FP32"
    
    print(f"–§–æ—Ä–º–∞—Ç: {model_format}")
    print(f"–¢–æ—á–Ω–æ—Å—Ç—å (–ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞): {model_precision}")
    if model_precision == "?":
        print("‚ö†Ô∏è –¢–∏–ø –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω - –Ω–∞–∑—ã–≤–∞–π—Ç–µ —Ñ–∞–π–ª—ã —è–≤–Ω–æ (fp16/int8)")
    print(f"‚ÑπÔ∏è –ö–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ –∑–∞–¥–∞–µ—Ç—Å—è –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ, –Ω–µ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ!")
    
    try:
        model = YOLO(args.model, task='segment')
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        print("\n–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–π—Ç–µ –º–æ–¥–µ–ª—å:")
        print("  ONNX:     python export_to_onnx.py --model yolo11n-seg.pt --format onnx")
        print("  TensorRT: python export_to_onnx.py --model yolo11n-seg.pt --format engine --half")
        print("  OpenVINO: python export_to_onnx.py --model yolo11n-seg.pt --format openvino")
        return
    
    print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    # –ö–∞–º–µ—Ä–∞
    cap = cv2.VideoCapture(args.camera)
    if not cap.isOpened():
        print(f"‚ùå –ö–∞–º–µ—Ä–∞ {args.camera} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
        return
    
    # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –∫–∞–º–µ—Ä—ã
    if args.width:
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, args.width)
    if args.height:
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, args.height)
    
    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps_cam = cap.get(cv2.CAP_PROP_FPS) or 30.0
    
    print(f"–ö–∞–º–µ—Ä–∞: {w}x{h} @ {fps_cam:.1f}fps")
    
    # Video writer
    writer = None
    if args.save:
        out_file = f"output_onnx_{time.strftime('%Y%m%d_%H%M%S')}.mp4"
        writer = cv2.VideoWriter(out_file, cv2.VideoWriter_fourcc(*'mp4v'), fps_cam, (w, h))
        print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ: {out_file}")
    
    print("\n–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: 'q' - –≤—ã—Ö–æ–¥, 's' - —Å–∫—Ä–∏–Ω—à–æ—Ç")
    print("="*70 + "\n")
    
    # –ü—Ä–æ–≥—Ä–µ–≤
    print("–ü—Ä–æ–≥—Ä–µ–≤ –º–æ–¥–µ–ª–∏...")
    dummy = np.zeros((h, w, 3), dtype=np.uint8)
    warmup_times = []
    for i in range(3):
        t_start = time.time()
        _ = model(dummy, conf=args.conf, iou=args.iou, device=args.device, verbose=False)
        warmup_times.append((time.time() - t_start) * 1000)
    print(f"‚úÖ –ì–æ—Ç–æ–≤–æ (–ø—Ä–æ–≥—Ä–µ–≤: {warmup_times[-1]:.1f}ms)\n")
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    times = []
    count = 0
    shots = 0
    avg_time = 0.0
    avg_fps = 0.0
    
    while True:
        t0 = time.time()
        
        ret, frame = cap.read()
        if not ret:
            print("‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫–∞–¥—Ä–∞")
            break
        
        # Inference —Å —è–≤–Ω—ã–º —É–∫–∞–∑–∞–Ω–∏–µ–º device
        results = model(frame, conf=args.conf, iou=args.iou, device=args.device, verbose=False)
        
        # –û—Ç—Ä–∏—Å–æ–≤–∫–∞
        annotated = results[0].plot()
        
        # –í—Ä–µ–º—è
        t1 = time.time()
        frame_time = (t1 - t0) * 1000
        times.append(frame_time)
        if len(times) > 30:
            times.pop(0)
        avg_time = sum(times) / len(times)
        avg_fps = 1000 / avg_time if avg_time > 0 else 0
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        num_obj = len(results[0].boxes) if results[0].boxes is not None else 0
        
        cv2.putText(annotated, f"Time: {avg_time:.1f}ms", (10, 30), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        cv2.putText(annotated, f"FPS: {avg_fps:.1f}", (10, 65), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        cv2.putText(annotated, f"{model_format} {model_precision}", (10, 100), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        cv2.putText(annotated, f"Device: {args.device.upper()}", (10, 130), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        cv2.putText(annotated, f"Objects: {num_obj}", (10, 160), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        
        cv2.imshow(f'YOLO11 {model_format}', annotated)
        
        if writer:
            writer.write(annotated)
        
        count += 1
        
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            break
        elif key == ord('s'):
            fname = f"screenshot_{time.strftime('%Y%m%d_%H%M%S')}.jpg"
            cv2.imwrite(fname, annotated)
            print(f"üì∏ {fname}")
            shots += 1
    
    cap.release()
    if writer:
        writer.release()
    cv2.destroyAllWindows()
    
    print(f"\n{'='*70}")
    print("–°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print(f"{'='*70}")
    if count > 0:
        print(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {avg_time:.1f}ms")
        print(f"–°—Ä–µ–¥–Ω–∏–π FPS: {avg_fps:.1f}")
    print(f"–ö–∞–¥—Ä–æ–≤: {count}")
    print(f"–°–∫—Ä–∏–Ω—à–æ—Ç–æ–≤: {shots}")
    print(f"{'='*70}")


if __name__ == "__main__":
    main()
